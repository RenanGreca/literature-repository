{"type": "primary", "year": "2019", "authors": "Land, Kathrin; Neumann, Eva-Maria; Ziegltrum, Simon; Li, Huaxia; Vogel-Heuser, Birgit", "author_keys": ["land_kathrin", "neumann_eva-maria", "ziegltrum_simon", "li_huaxia", "vogel-heuser_birgit"], "title": "An Industrial Evaluation of Test Prioritisation Criteria and Metrics", "bibtex": "land_industrial_2019", "abstract": "Automated production systems become more and more complex. This makes it\n increasingly difficult to keep track of performed changes and already \nexecuted test cases. This endangers the systems quality as the risk of \nmissing important test cases while planning the test execution is high, \nespecially for testers with little experience. To face this challenge, \ntesters should be supported by an automatic test prioritisation based on\n metrics in selecting the right test cases for the test execution. In \nindustry, many different test prioritisation criteria and strategies are\n used for this purpose. In an industrial interview, experts discussed \nand ranked prioritisation criteria that are currently used within the \nrespective companies. As a result, this paper presents the cactus \nprioritisation model, which graphically resembles the industrial ranking\n and weighting of the criteria. Based on the prioritisation cactus and \nits criteria, a simple prioritisation metric is introduced to determine \nthe utility of each test case regarding the system under test. The test \ncases are prioritised according to their descending utility. \nFurthermore, approaches and metrics to realise the different individual \nprioritisation criteria are proposed.", "published_in": "2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)\n ", "publisher": "IEEE", "doi": "10.1109/SMC.2019.8914505", "date": "2019-11-28", "tcp": "X", "tcs": "", "tsr": "", "tsa": "", "ind_motivation": "TRUE", "ind_evaluation": "N/A", "exp_subjects": "", "ind_partner": "Undisclosed industrial partner (Germany)", "ind_author": "FALSE", "prac_feedback": "TRUE", "avai_tool": "FALSE", "put_practice": "FALSE", "suppl_url": "", "approach": "N/A", "metrics": "N/A", "open_challenges": "When prioritizing, should the focus be entirely on the safety-critical tests, or should some other tests be sprinkled in-between?"}