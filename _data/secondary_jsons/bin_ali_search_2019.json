{"year": "2019", "authors": "bin Ali, Nauman; Engstr\u00f6m, Emelie; Taromirad, Masoumeh; Mousavi, Mohammad Reza; Minhas, Nasir Mehmood; Helgesson, Daniel; Kunze, Sebastian; Varshosaz, Mahsa", "title": "On the search for industry-relevant regression testing research", "bibtex": "bin_ali_search_2019", "abstract": "Regression testing is a means to assure that a change in the software, or its execution environment, does not introduce new defects. It involves the expensive undertaking of rerunning test cases. Several techniques have been proposed to reduce the number of test cases to execute in regression testing, however, there is no research on how to assess industrial relevance and applicability of such techniques. We conducted a systematic literature review with the following two goals: firstly, to enable researchers to design and present regression testing research with a focus on industrial relevance and applicability and secondly, to facilitate the industrial adoption of such research by addressing the attributes of concern from the practitioners' perspective. Using a reference-based search approach, we identified 1068 papers on regression testing. We then reduced the scope to only include papers with explicit discussions about relevance and applicability (i.e. mainly studies involving industrial stakeholders). Uniquely in this literature review, practitioners were consulted at several steps to increase the likelihood of achieving our aim of identifying factors important for relevance and applicability. We have summarised the results of these consultations and an analysis of the literature in three taxonomies, which capture aspects of industrial-relevance regarding the regression testing techniques. Based on these taxonomies, we mapped 38 papers reporting the evaluation of 26 regression testing techniques in industrial settings. \u00a9 2019, The Author(s).", "published_in": "Empirical Software Engineering", "publisher": "Springer", "doi": "10.1007/s10664-018-9670-1", "date": "2019-02-12", "tcp": "X", "tcs": "X", "tsr": "X", "tsa": "", "paper_count": "38", "years_covered": "2002-2017", "systematic": "?", "approach": "Out of the 38 PS considered they classify 26 distinct techniques that are classified according to their taxonomy (Table 5 in the paper)", "metrics": "Classify the possible effects of improvement into 3 categories: coverage, efficiency&effectiveness, awareness. In turn, coverage mainly involved \"feature\" and \"combinatorial\": most papers considered code coverage, but this was considered not important by the practitiones. Eff&eff involved: test size reduction, test time reduction, improved precision, less time for fault detection, reduced resources, improved fault detection, also wrt severe ones, and reduced cost of failures. Finally awareness onl;y measured increased transparency", "conclusions": "One important result for researchers is their Table 4 in which they introduce a taxonomy of relevant factors (validated by three senior testers from industry) classied in scope/context/effect/information. (I wonder whether in our secondary study we should take this into account when we classify primary studies?)", "open_challenges": "coverage information is only partially relevant to practitioners; context information is neglected; focus should be on severe faults and cost reduction; address industrial context factors; study people-related factors"}